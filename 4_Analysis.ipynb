{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf, hour\n",
    "from pyspark.sql.types import IntegerType, LongType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will retrieve, process and display the data to be able to draw some conclusions. Most of these analyses concern monthly evolutions of certain quantities (total number of trip, ...). In order not to have to rewrite code to plot the data, we will write a function.\n",
    "\n",
    "For each dataset we will calculate the data and store them in a json, the function will then fetch the data in the different json files to plot the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly(data_dir, data_label, title):\n",
    "    filenames = sorted(glob.glob(\"plot_data/{}/*.json\".format(data_dir)))\n",
    "    \n",
    "    n = len(filenames)\n",
    "    fig, ax = plt.subplots(n,1, figsize = (20,n*5))\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    for i, filename in zip(range(n), filenames):\n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "            months = data['months']\n",
    "            months = [datetime(year=int(month[0:4]), \n",
    "                               month=int(month[5:]), day=1) for month in months]\n",
    "            values = data['values']\n",
    "            \n",
    "            series = pd.Series(values, index=months)\n",
    "            if n > 1:\n",
    "                a = ax[i]\n",
    "            else:\n",
    "                a = ax\n",
    "            series.plot(style='-', ax=a)\n",
    "            a.set_ylabel(data_label)\n",
    "            a.set_title('{} dataset'.format(os.path.basename(filename)[:-5]))\n",
    "            a.tick_params(labelbottom=True)\n",
    "            \n",
    "    fig.suptitle(title, fontsize=26)\n",
    "            \n",
    "    plt.savefig('figures/{}.png'.format(data_dir))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the filename\n",
    "hdfs_path = 'hdfs://public00:8020/user/hpda000034/infoh600/clean'\n",
    "local_path = '/home/hpda00034/infoh600/sampled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HADOOP_CONF_DIR']=\"/etc/hadoop/conf\"\n",
    "\n",
    "# python configuration\n",
    "os.environ['PYSPARK_PYTHON']=\"/usr/local/anaconda3/bin/python\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']=\"/usr/local/anaconda3/bin/python\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles, SQLContext\n",
    "\n",
    "\n",
    "# remove old spark session\n",
    "try: \n",
    "    spark\n",
    "    print(\"Spark application already started. Terminating existing application and starting new one\")\n",
    "    spark.stop()\n",
    "except: \n",
    "    pass\n",
    "\n",
    "# Create a new spark session, with YARN as resource manager, requesting 4 worker nodes.\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.executor.instances\",\"4\") \\\n",
    "    .appName(\"project_ceci18\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create slq spark context\n",
    "sc=spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Monthly total number of trips (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"yellow\"\n",
    "\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "n_trips = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    # load the dataframe from csv\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True)\n",
    "    # count the rows\n",
    "    count = trips.count()\n",
    "    n_trips.append(count)\n",
    "    months.append(filename[-11:-4])\n",
    "\n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': n_trips\n",
    "}\n",
    "\n",
    "with open('plot_data/4_1/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_1', 'number of trips', 'Monthly total number of trips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_1.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Monthly total number of trips in Manhattan and Brooklyn (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recuperate the zone ids for Manhattan and Brooklyn\n",
    "zones = pd.read_csv('shape_files/zones.csv')\n",
    "\n",
    "man = [loc_id-1 for loc_id in \n",
    "       list(zones.loc[zones['Borough']=='Manhattan', 'LocationID'])]\n",
    "bro = [loc_id-1 for loc_id in \n",
    "       list(zones.loc[zones['Borough']=='Brooklyn', 'LocationID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"yellow\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "n_trips = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    # load the dataframe from csv\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True).persist()\n",
    "   \n",
    "    # count trip in Manhattan\n",
    "    man_trips = trips.filter(trips.pulocationid.cast(IntegerType()).isin(man)) \\\n",
    "                     .filter(trips.dolocationid.cast(IntegerType()).isin(man))\n",
    "    count_man = man_trips.count()\n",
    "    \n",
    "    # count trip in Brooklyn\n",
    "    bro_trips = trips.filter(trips.pulocationid.cast(IntegerType()).isin(bro)) \\\n",
    "                     .filter(trips.dolocationid.cast(IntegerType()).isin(bro))\n",
    "    count_bro = bro_trips.count()\n",
    "    \n",
    "    n_trips.append(count_man + count_bro)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': n_trips\n",
    "}\n",
    "\n",
    "with open('plot_data/4_2/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_2', 'number of trips', 'Monthly total number of trips (Man et Bro)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_2.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: For the FHV dataset, for a long time the graph is at 0 because for a long time the place of dropoff was not recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Monthly total receipts (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt_column = {'green': ['fare_amount', 'extra', 'mta_tax', \n",
    "                            'tolls_amount', 'ehail_fee'],\n",
    "                  'yellow': ['fare_amount', 'extra', 'mta_tax', \n",
    "                             'tolls_amount']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"yellow\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "total_receipts = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    # load the dataframe from csv\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True).persist()\n",
    "    \n",
    "    # compute total receipt in a new column\n",
    "    trips = trips.withColumn('receipt',sum(trips[x] for x in receipt_column[dataset]))\n",
    "    # sum on the new receipt column\n",
    "    total_receipt = trips.agg(F.sum('receipt')).collect()[0][0]\n",
    "    \n",
    "    total_receipts.append(total_receipt)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': total_receipts\n",
    "}\n",
    "\n",
    "with open('plot_data/4_3/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_3', 'total receipt ($)', 'Monthly total receipts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_3.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is the yellow taxi company that makes the most revenue, mainly because it makes many more trips, as can be seen in section 4.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Monthly average receipt (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt_column = {'green': ['fare_amount', 'extra', 'mta_tax', \n",
    "                            'tolls_amount', 'ehail_fee']\n",
    "                  'yellow': ['fare_amount', 'extra', 'mta_tax', \n",
    "                             'tolls_amount']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"yellow\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "average_receipts = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    # load the dataframe from csv\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True).persist()\n",
    "    \n",
    "    # compute total receipt\n",
    "    total_receipt = trips.withColumn('receipt',sum(trips[x] for x in receipt_column[dataset])) \\\n",
    "                         .agg(F.sum('receipt')).collect()[0][0]\n",
    "    \n",
    "    # compute the number of trips\n",
    "    n_trips = trips.count()\n",
    "    \n",
    "    average_receipt = total_receipt/n_trips\n",
    "    average_receipts.append(average_receipt)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': average_receipts\n",
    "}\n",
    "\n",
    "with open('plot_data/4_4/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_4', 'average receipt ($)', 'Monthly average receipts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_4.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Monthly average cost per in-progress-minute (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt_column = {'green': ['fare_amount', 'extra', 'mta_tax', \n",
    "                            'tolls_amount', 'ehail_fee'],\n",
    "                  'yellow': ['fare_amount', 'extra', 'mta_tax', \n",
    "                             'tolls_amount']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"yellow\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "pickup_datetime = {'yellow': 'tpep_pickup_datetime',\n",
    "                   'green': 'lpep_pickup_datetime'}\n",
    "\n",
    "dropoff_datetime = {'yellow': 'tpep_dropoff_datetime',\n",
    "                    'green': 'lpep_dropoff_datetime'}\n",
    "\n",
    "\n",
    "def time_delta(end,start):\n",
    "    end = end.cast(LongType())\n",
    "    start = start.cast(LongType())\n",
    "    delta = (end-start)/60\n",
    "    return delta\n",
    "\n",
    "f = udf(time_delta, IntegerType())\n",
    "\n",
    "\n",
    "average_receipts = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    # load the dataframe from csv\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True)\\\n",
    "                      .fillna({pickup_datetime[dataset]:0,\n",
    "                               dropoff_datetime[dataset]:0})\\\n",
    "                      .persist()\n",
    "    \n",
    "    # filter empty datetime\n",
    "    trips = trips.filter(trips[pickup_datetime[dataset]].cast(LongType()) != 0) \\\n",
    "                 .filter(trips[dropoff_datetime[dataset]].cast(LongType()) != 0) \\\n",
    "                 .persist()\n",
    "    \n",
    "    # compute total time of the trips\n",
    "    total_time = trips.withColumn('time',time_delta(trips[dropoff_datetime[dataset]], \n",
    "                                                    trips[pickup_datetime[dataset]])) \\\n",
    "                      .agg(F.sum('time')).collect()[0][0]\n",
    "    \n",
    "    # compute total receipt\n",
    "    total_receipt = trips.withColumn('receipt',sum(trips[x] for x in receipt_column[dataset])) \\\n",
    "                         .agg(F.sum('receipt')).collect()[0][0]\n",
    "    \n",
    "    average_receipt = total_receipt/total_time\n",
    "    average_receipts.append(average_receipt)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': average_receipts\n",
    "}\n",
    "\n",
    "with open('plot_data/4_5/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_5', 'cost per minutes ($)', 'Average cost per in progress minute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_5.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to 2016, the price per minute was equivalent for yellow and green taxis.\n",
    "\n",
    "After 2016, green taxis became cheaper per minute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Monthly average tip (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"yellow\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "average_tips = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    # load the dataframe from csv\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True).persist()\n",
    "    \n",
    "    # compute total of the tips\n",
    "    total_tip = trips.agg(F.sum('tip_amount')).collect()[0][0]\n",
    "    \n",
    "    # compute number of trips\n",
    "    n_trips = trips.count()\n",
    "    \n",
    "    average_tip = total_tip/n_trips\n",
    "    average_tips.append(average_tip)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': average_tips\n",
    "}\n",
    "\n",
    "with open('plot_data/4_6/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_6', 'average tip ($)', 'Monthly average tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_6.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, yellow taxi drivers get the biggest tips."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Median monthly average trip speed (per borough, per dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index for each borough\n",
    "zones = pd.read_csv('shape_files/zones.csv')\n",
    "\n",
    "manhattan = [loc_id-1 for loc_id in \n",
    "             list(zones.loc[zones['Borough']=='Manhattan', 'LocationID'])]\n",
    "brooklyn = [loc_id-1 for loc_id in \n",
    "            list(zones.loc[zones['Borough']=='Brooklyn', 'LocationID'])]\n",
    "queens = [loc_id-1 for loc_id in \n",
    "          list(zones.loc[zones['Borough']=='Queens', 'LocationID'])]\n",
    "bronx = [loc_id-1 for loc_id in \n",
    "         list(zones.loc[zones['Borough']=='Bronx', 'LocationID'])]\n",
    "staten = [loc_id-1 for loc_id in \n",
    "          list(zones.loc[zones['Borough']=='Staten Island', 'LocationID'])]\n",
    "\n",
    "boroughs = {\n",
    "    'Manhattan': manhattan,\n",
    "    'Brooklyn': brooklyn,\n",
    "    'Queens': queens,\n",
    "    'Bronx': bronx,\n",
    "    'Staten Island': staten\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"yellow\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "pickup_datetime = {'yellow': 'tpep_pickup_datetime',\n",
    "                    'green': 'lpep_pickup_datetime'}\n",
    "\n",
    "dropoff_datetime = {'yellow': 'tpep_dropoff_datetime',\n",
    "                    'green': 'lpep_dropoff_datetime'}\n",
    "\n",
    "\n",
    "def time_delta(end,start):\n",
    "    end = end.cast(LongType())\n",
    "    start = start.cast(LongType())\n",
    "    delta = (end-start)/60\n",
    "    return delta\n",
    "\n",
    "f = udf(time_delta, IntegerType())\n",
    "\n",
    "months = []\n",
    "median_speeds = []\n",
    "for filename in filenames:\n",
    "    boroughs_median_speed = {}\n",
    "    print(filename)\n",
    "    for borough, indexes in boroughs.items():\n",
    "        print(\"   -{}\".format(borough))\n",
    "        # load the dataframe from csv\n",
    "        trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                    header=True,\n",
    "                                    inferSchema=True)\\\n",
    "                          .fillna({pickup_datetime[dataset]:0,\n",
    "                                   dropoff_datetime[dataset]:0})\\\n",
    "                          .persist()\n",
    "\n",
    "        # filter empty datetime\n",
    "        trips = trips.filter(trips[pickup_datetime[dataset]].cast(LongType()) != 0) \\\n",
    "                     .filter(trips[dropoff_datetime[dataset]].cast(LongType()) != 0) \\\n",
    "        \n",
    "        # filter borough\n",
    "        trips = trips.filter(trips.pulocationid.cast(IntegerType()).isin(indexes)) \\\n",
    "                     .filter(trips.dolocationid.cast(IntegerType()).isin(indexes))\n",
    "\n",
    "        # compute total time of the trips\n",
    "        trips = trips.withColumn('time',time_delta(trips[dropoff_datetime[dataset]], \n",
    "                                                   trips[pickup_datetime[dataset]])) \\\n",
    "                          \n",
    "\n",
    "        # compute speed\n",
    "        trips = trips.withColumn('speed',trips['trip_distance']/trips['time']) \n",
    "\n",
    "        # compute median speed\n",
    "        \n",
    "        median_speed = trips.approxQuantile('speed', [0.5], 0)\n",
    "        if len(median_speed) != 0:\n",
    "            boroughs_median_speed[borough] = median_speed[0]\n",
    "        else:\n",
    "            boroughs_median_speed[borough] = None\n",
    "        \n",
    "    median_speeds.append(boroughs_median_speed)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': median_speeds\n",
    "}\n",
    "\n",
    "with open('plot_data/4_7/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the result\n",
    "\n",
    "filenames = sorted(glob.glob(\"plot_data/4_7/*.json\"))\n",
    "\n",
    "n = len(filenames)\n",
    "fig, ax = plt.subplots(n,1, figsize = (20,n*5))\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "for i, filename in zip(range(n), filenames):\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)\n",
    "        months = data['months']\n",
    "        months = [datetime(year=int(month[0:4]), \n",
    "                           month=int(month[5:]), day=1) for month in months]\n",
    "        series = data['values']\n",
    "\n",
    "        series = pd.DataFrame(series, index=months)\n",
    "        series.columns = columns=['Manhattan', 'Brooklyn', 'Queens', 'Bronx', 'Staten Island']\n",
    "            \n",
    "        series.plot(style='-', ax=ax[i])\n",
    "        ax[i].set_ylabel('speed (miles/minutes)')\n",
    "        ax[i].set_title('{} dataset'.format(os.path.basename(filename)[:-5]))\n",
    "        ax[i].tick_params(labelbottom=True)\n",
    "\n",
    "fig.suptitle(\"Median monthly average trip speed (per borough)\", fontsize=26)\n",
    "\n",
    "plt.savefig('./figures/4_7.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_7.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8.  How long does it take to get to a NYC airport ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manhanttan midtown indexes\n",
    "man_mid = [161, 162, 163, 164]\n",
    "\n",
    "# get the index for each airport\n",
    "zones = pd.read_csv('shape_files/zones.csv')\n",
    "\n",
    "new = [loc_id for loc_id in \n",
    "      list(zones.loc[zones['Zone']=='Newark Airport', 'LocationID'])][0]\n",
    "jfk = [loc_id for loc_id in \n",
    "       list(zones.loc[zones['Zone']=='JFK Airport', 'LocationID'])][0]\n",
    "lg = [loc_id for loc_id in \n",
    "      list(zones.loc[zones['Zone']=='LaGuardia Airport', 'LocationID'])][0]\n",
    "\n",
    "airports =  {\n",
    "    'Newark Airport': new,\n",
    "    'JFK Airport': jfk,\n",
    "    'LaGuardia Airport': lg\n",
    "}\n",
    "\n",
    "# generate hours\n",
    "hours = list(range(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"yellow\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "pickup_datetime = {'yellow': 'tpep_pickup_datetime',\n",
    "                    'green': 'lpep_pickup_datetime'}\n",
    "\n",
    "dropoff_datetime = {'yellow': 'tpep_dropoff_datetime',\n",
    "                    'green': 'lpep_dropoff_datetime'}\n",
    "\n",
    "average_tips = []\n",
    "months = []\n",
    "\n",
    "first = True\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    # load the dataframe from csv\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True)\\\n",
    "                                .fillna({pickup_datetime[dataset]:0,\n",
    "                                         dropoff_datetime[dataset]:0})\n",
    "    \n",
    "    # filter departur in manhattan midtown\n",
    "    trips = trips.filter(trips.pulocationid.cast(IntegerType()).isin(man_mid))\n",
    "\n",
    "    # filter empty datetime\n",
    "    trips = trips.filter(trips[pickup_datetime[dataset]].cast(LongType()) != 0) \\\n",
    "                 .filter(trips[dropoff_datetime[dataset]].cast(LongType()) != 0) \\\n",
    "                 .persist()\n",
    "\n",
    "    # union on all the files of the dataset\n",
    "    if first:\n",
    "        man_mid_trips = trips\n",
    "        print(\"first\")\n",
    "        first = False\n",
    "\n",
    "    else:\n",
    "        man_mid_trips = man_mid_trips.union(trips)\n",
    "        \n",
    "\n",
    "median_times = {}\n",
    "for airport, index in airports.items():\n",
    "    print(airport)\n",
    "    # filter arrival in teh current airport\n",
    "    airport_trips = man_mid_trips.filter(man_mid_trips.dolocationid.cast(IntegerType()) == index)\\\n",
    "                                 .persist()\n",
    "\n",
    "    median_times_by_hour = {}\n",
    "    for h in hours:\n",
    "        print(\"  -{}\".format(h))\n",
    "        # filter departur in the current hour\n",
    "        h_trips = airport_trips.filter(hour(airport_trips[pickup_datetime[dataset]]) == h)\n",
    "        \n",
    "        # compute time of the trips\n",
    "        trips = h_trips.withColumn('time',time_delta(h_trips[dropoff_datetime[dataset]], \n",
    "                                                     h_trips[pickup_datetime[dataset]])) \\\n",
    "        \n",
    "        # compute the median time on the remaining rows\n",
    "        median_time = trips.approxQuantile('time', [0.5], 0)\n",
    "    \n",
    "        if len(median_time) != 0:\n",
    "            median_times_by_hour[str(h)] = median_time[0]\n",
    "        else:\n",
    "            median_times_by_hour[str(h)] = None\n",
    "    \n",
    "    median_times[airport] = median_times_by_hour\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': median_times\n",
    "}\n",
    "\n",
    "with open('plot_data/4_8/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import table\n",
    "\n",
    "# load data from json\n",
    "with open('./plot_data/4_8/yellow.json') as f:\n",
    "    data = json.load(f)\n",
    "    data = data['values']\n",
    "\n",
    "# build dataframe\n",
    "columns = list(range(0,24))\n",
    "rows = list(data.keys())\n",
    "data = list(data.values())\n",
    "df = [list(d.values()) for d in data]\n",
    "df = pd.DataFrame(df, columns=columns, index=rows).T\n",
    "df = df.applymap(lambda x: round(x,2))\n",
    "\n",
    "# plot table\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,5))\n",
    "ax.axis('off')\n",
    "table(ax, df, loc='upper right')\n",
    "\n",
    "plt.savefig('./figures/4_8.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_8.png\" width=\"600\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows the median travel times (in minutes) to the different airports from Manhattan midtown at all hours of the day  of the day (for example, 1 corresponds to the period 1:00:00 to 1:59:59). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop spark\n",
    "try: \n",
    "    spark.stop()\n",
    "except: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
