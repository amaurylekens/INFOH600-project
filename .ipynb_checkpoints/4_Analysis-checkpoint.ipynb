{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType, LongType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we will retrieve, process and display the data to be able to draw some conclusions. Most of these analyses concern monthly evolutions of certain quantities (total number of trip, ...). In order not to have to rewrite code to plot the data, we will write a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monthly(data_dir, data_label, title):\n",
    "    filenames = sorted(glob.glob(\"plot_data/{}/*.json\".format(data_dir)))\n",
    "    \n",
    "    n = len(filenames)\n",
    "    fig, ax = plt.subplots(n,1, figsize = (20,n*8))\n",
    "    fig.autofmt_xdate()\n",
    "    \n",
    "    for i, filename in zip(range(n), filenames):\n",
    "        with open(filename) as f:\n",
    "            data = json.load(f)\n",
    "            months = data['months']\n",
    "            months = [datetime(year=int(month[0:4]), \n",
    "                               month=int(month[5:]), day=1) for month in months]\n",
    "            values = data['values']\n",
    "            \n",
    "            series = pd.Series(values, index=months)\n",
    "            if n > 1:\n",
    "                a = ax[i]\n",
    "            else:\n",
    "                a = ax\n",
    "            series.plot(style='-', ax=a)\n",
    "            a.set_ylabel(data_label)\n",
    "            a.set_title('{} dataset'.format(os.path.basename(filename)[:-5]))\n",
    "            a.tick_params(labelbottom=True)\n",
    "            \n",
    "    plt.savefig('figures/{}.png'.format(data_dir))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the filename\n",
    "hdfs_path = 'hdfs://public00:8020/user/hpda000034/infoh600/clean'\n",
    "local_path = '/home/hpda00034/infoh600/sampled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HADOOP_CONF_DIR']=\"/etc/hadoop/conf\"\n",
    "\n",
    "# python configuration\n",
    "os.environ['PYSPARK_PYTHON']=\"/usr/local/anaconda3/bin/python\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON']=\"/usr/local/anaconda3/bin/python\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles, SQLContext\n",
    "\n",
    "\n",
    "# remove old spark session\n",
    "try: \n",
    "    spark\n",
    "    print(\"Spark application already started. Terminating existing application and starting new one\")\n",
    "    spark.stop()\n",
    "except: \n",
    "    pass\n",
    "\n",
    "# Create a new spark session, with YARN as resource manager, requesting 4 worker nodes.\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.executor.instances\",\"4\") \\\n",
    "    .appName(\"project_ceci18\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create spark context\n",
    "sc=spark.sparkContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Monthly total number of trips (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"fhvhv\"\n",
    "\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "n_trips = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    df = sqlContext.read.csv(\"./integrated/{}/{}\".format(dataset, filename), header=True)\n",
    "    count = df.count()\n",
    "    n_trips.append(count)\n",
    "    months.append(filename[-11:-4])\n",
    "\n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': n_trips\n",
    "}\n",
    "print(data)\n",
    "\n",
    "with open('plot_data/4_1/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_1', 'number of trips', 'Monthly total number of trips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_1.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Monthly total number of trips in Manhattan and Brooklyn (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = pd.read_csv('shape_files/zones.csv')\n",
    "zones.head()\n",
    "\n",
    "man = [loc_id-1 for loc_id in \n",
    "       list(zones.loc[zones['Borough']=='Manhattan', 'LocationID'])]\n",
    "bro = [loc_id-1 for loc_id in \n",
    "       list(zones.loc[zones['Borough']=='Brooklyn', 'LocationID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4b56c2ecb0e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"fhvhv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}_*.csv\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn_trips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = \"fhvhv\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "n_trips = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    trips = sqlContext.read.csv(\"./integrated/{}/{}\".format(dataset, filename), header=True).persist()\n",
    "    man_trips = trips.filter(trips.pulocationid.cast(IntegerType()).isin(man)) \\\n",
    "                     .filter(trips.dolocationid.cast(IntegerType()).isin(man))\n",
    "    bro_trips = trips.filter(trips.pulocationid.cast(IntegerType()).isin(bro)) \\\n",
    "                     .filter(trips.dolocationid.cast(IntegerType()).isin(bro))\n",
    "    count_man = man_trips.count()\n",
    "    count_bro = bro_trips.count()\n",
    "    n_trips.append(count_man + count_bro)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': n_trips\n",
    "}\n",
    "\n",
    "with open('plot_data/4_2/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_2', 'number of trips', 'Monthly number of trips (Man et Bro)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_2.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Monthly total receipts (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt_column = ['fare_amount', 'extra', 'mta_tax', 'tolls_amount', 'ehail_fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"green\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "total_receipts = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True).fillna({'fare_amount':0, 'mta_tax':0, \n",
    "                                                          'extra':0, 'tolls_amount':0,\n",
    "                                                          'ehail_fee': 0}).persist()\n",
    "    trips = trips.withColumn('receipt',sum(trips[x] for x in receipt_column))\n",
    "    total_receipt = trips.agg(F.sum('receipt')).collect()[0][0]\n",
    "    total_receipts.append(total_receipt)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': total_receipts\n",
    "}\n",
    "\n",
    "with open('plot_data/4_3/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_3', 'total receipt', 'Monthly total receipts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_3.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Monthly average receipt (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"green\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "\n",
    "average_receipts = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True).fillna({'fare_amount':0, 'mta_tax':0, \n",
    "                                                          'extra':0, 'tolls_amount':0,\n",
    "                                                          'ehail_fee': 0}).persist()\n",
    "    total_receipt = trips.withColumn('receipt',sum(trips[x] for x in receipt_column)) \\\n",
    "                         .agg(F.sum('receipt')).collect()[0][0]\n",
    "    n_trips = trips.count()\n",
    "    average_receipt = total_receipt/n_trips\n",
    "    average_receipts.append(average_receipt)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': average_receipts\n",
    "}\n",
    "\n",
    "with open('plot_data/4_4/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_4', 'average receipt', 'Monthly total receipts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_4.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Monthly average cost per in-progress-minute (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipt_column = ['fare_amount', 'extra', 'mta_tax', 'tolls_amount', 'ehail_fee']\n",
    "\n",
    "dataset = \"green\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "def time_delta(end,start):\n",
    "    end = end.cast(LongType())\n",
    "    start = start.cast(LongType())\n",
    "    delta = (end-start)/60\n",
    "    return delta\n",
    "\n",
    "f = udf(time_delta, IntegerType())\n",
    "\n",
    "\n",
    "average_receipts = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True).fillna({'fare_amount':0, 'mta_tax':0, \n",
    "                                                          'extra':0, 'tolls_amount':0,\n",
    "                                                          'ehail_fee': 0}).persist()\n",
    "    trips = trips.filter(trips.lpep_dropoff_datetime.cast(LongType()) != 0) \\\n",
    "                 .filter(trips.lpep_pickup_datetime.cast(LongType()) != 0) \\\n",
    "                 .persist()\n",
    "    total_time = trips.withColumn('time',time_delta(trips['lpep_dropoff_datetime'], \n",
    "                                                    trips['lpep_pickup_datetime'])) \\\n",
    "                      .agg(F.sum('time')).collect()[0][0]\n",
    "    total_receipt = trips.withColumn('receipt',sum(trips[x] for x in receipt_column)) \\\n",
    "                         .agg(F.sum('receipt')).collect()[0][0]\n",
    "    average_receipt = total_receipt/total_time\n",
    "    average_receipts.append(average_receipt)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': average_receipts\n",
    "}\n",
    "\n",
    "with open('plot_data/4_5/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_5', 'cost per minutes', 'Average cost per in progress minute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_5.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Monthly average tip (per dataset type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"green\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "average_tips = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True).fillna({'tip_amount':0}).persist()\n",
    "    total_tip = trips.agg(F.sum('tip_amount')).collect()[0][0]\n",
    "    n_trips = trips.count()\n",
    "    average_tip = total_tip/n_trips\n",
    "    average_tips.append(average_tip)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': average_tips\n",
    "}\n",
    "\n",
    "with open('plot_data/4_6/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_6', 'total tip', 'Average tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/4_6.png\" width=\"1000\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7. Median monthly average trip speed (per borough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"green\"\n",
    "filenames = sorted(glob.glob(\"{}/{}_*.csv\".format(local_path, dataset)))\n",
    "filenames = [os.path.basename(filename) for filename in filenames]\n",
    "\n",
    "\n",
    "def time_delta(end,start):\n",
    "    end = end.cast(LongType())\n",
    "    start = start.cast(LongType())\n",
    "    delta = (end-start)/60\n",
    "    return delta\n",
    "\n",
    "f = udf(time_delta, IntegerType())\n",
    "\n",
    "\n",
    "median_speeds = []\n",
    "months = []\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    trips = sqlContext.read.csv(\"./clean/{}/{}\".format(dataset, filename), \n",
    "                                header=True,\n",
    "                                inferSchema=True)\\\n",
    "                      .na.fill(0)\n",
    "    trips = trips.filter(trips.lpep_dropoff_datetime.cast(LongType()) != 0) \\\n",
    "                 .filter(trips.lpep_pickup_datetime.cast(LongType()) != 0) \\\n",
    "                 .withColumn('time',time_delta(trips['lpep_dropoff_datetime'], \n",
    "                                                    trips['lpep_pickup_datetime'])) \n",
    "\n",
    "    trips = trips.withColumn('speed',trips['trip_distance']/trips['time']) \n",
    "    median_speed = trips.approxQuantile('speed', [0.5], 0)[0]\n",
    "    median_speeds.append(median_speed)\n",
    "    months.append(filename[-11:-4])\n",
    "    \n",
    "data = {\n",
    "    'months': months,\n",
    "    'values': median_speeds\n",
    "}\n",
    "\n",
    "with open('plot_data/4_7/{}.json'.format(dataset), 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_monthly('4_7', 'speed', 'Average speed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8.  How long does it take to get to a NYC airport ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop spark\n",
    "try: \n",
    "    spark.stop()\n",
    "except: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
